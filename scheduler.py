import json
import subprocess
import time
import uuid
import os
import sys
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED

class PieScheduler:
    def __init__(self, workflow_path):
        self.workflow_path = os.path.abspath(workflow_path)
        self.results = {} 
        self.run_id = f"run_{uuid.uuid4().hex[:8]}"
        
        print(f"[Scheduler] Init checking...")
        print(f"  - Workflow: {self.workflow_path}")
        print(f"  - Mode:     Parallel Execution (ThreadPool)")

        if not os.path.exists(self.workflow_path):
            raise FileNotFoundError(f"Workflow file not found: {self.workflow_path}")
            
        self.workflow = self._load_workflow()

    def _load_workflow(self):
        with open(self.workflow_path, 'r') as f:
            return json.load(f)

    def _get_upstream_data(self, dependencies):
        upstream_data = {}
        for dep_id in dependencies:
            # è¿™é‡Œçš„è¯»å–éœ€è¦æ³¨æ„çº¿ç¨‹å®‰å…¨ï¼Œä½†åœ¨ Python GIL ä¸‹å­—å…¸è¯»å–é€šå¸¸æ˜¯åŽŸå­æ€§çš„ï¼Œ
            # ä¸”æˆ‘ä»¬çš„é€»è¾‘ä¿è¯äº†åªæœ‰ä¾èµ–å®ŒæˆåŽæ‰ä¼šè¯»å–ï¼Œæ‰€ä»¥æ˜¯å®‰å…¨çš„ã€‚
            if dep_id in self.results:
                upstream_data[dep_id] = self.results[dep_id]['content']
            else:
                raise Exception(f"Dependency {dep_id} not executed yet!")
        return upstream_data

    def run_node(self, node):
        node_id = node['id']
        raw_image_path = node['image']
        
        workflow_dir = os.path.dirname(self.workflow_path)
        wasm_path = os.path.join(workflow_dir, raw_image_path)
        wasm_path = os.path.abspath(wasm_path)

        start_ts = datetime.now().strftime("%H:%M:%S.%f")[:12]
        print(f"[{start_ts}] [Scheduler] âž¤ [Start] {node_id}")
        
        if not os.path.exists(wasm_path):
            print(f"[Error] Wasm file not found at: {wasm_path}")
            return False

        try:
            dependencies = node.get("dependencies", [])
            
            # [Fix] æ˜¾å¼èŽ·å–çˆ¶èŠ‚ç‚¹ IDï¼Œä¸å†åš Magic String æ³¨å…¥
            parent_node_id = dependencies[0] if dependencies else None

            # [Fix] æž„é€  input_payloadï¼Œæ˜Žç¡®ä¼ é€’æ‹“æ‰‘ä¿¡æ¯
            input_payload = {
                "run_id": self.run_id,
                "node_id": node_id,
                "parent_node_id": parent_node_id, # æ–°å¢žå­—æ®µ
                "input_context": node.get("config", {}),
                "upstream_results": self._get_upstream_data(dependencies)
            }
            input_json_str = json.dumps(input_payload)

            cmd = [
                "pie-cli", "submit",
                wasm_path,
                "--", 
                "--input", input_json_str
            ]

            env = os.environ.copy()
            env["RUST_LOG"] = "error"

            start_time = time.time()
            result = subprocess.run(
                cmd, capture_output=True, text=True, encoding='utf-8',
                cwd=os.getcwd(), env=env
            )
            elapsed = time.time() - start_time

            if result.returncode != 0:
                print(f"[Scheduler] âŒ Node {node_id} failed:\n{result.stderr}")
                return False

            raw_output = result.stdout.strip()
            clean_content = raw_output 
            
            if "Completed:" in raw_output: clean_content = raw_output.split("Completed:", 1)[1].strip()
            
            # æ¸…æ´—å¯èƒ½çš„ tag è¾“å‡ºï¼Œä¿æŒæ—¥å¿—å¹²å‡€
            if "[SAVE:" in clean_content:
                # ç®€å•çš„å­—ç¬¦ä¸²åˆ‡åˆ†æ¸…æ´—ï¼Œé˜²æ­¢æ—¥å¿—å¤ªé•¿
                pass

            end_ts = datetime.now().strftime("%H:%M:%S.%f")[:12]
            print(f"[{end_ts}] [Scheduler] âœ… [Finish] {node_id} ({elapsed:.2f}s)")
            
            self.results[node_id] = {"content": clean_content, "status": "success"}
            return True

        except Exception as e:
            print(f"[Scheduler] System Error in {node_id}: {e}")
            return False

    def run(self):
        print(f"=== Starting Workflow: {self.workflow['name']} (ID: {self.run_id}) ===")
        
        all_nodes = {n['id']: n for n in self.workflow['nodes']}
        pending_ids = set(all_nodes.keys())
        completed_ids = set()
        running_ids = set() # è®°å½•æ­£åœ¨è¿è¡Œçš„èŠ‚ç‚¹

        # åˆ›å»ºçº¿ç¨‹æ± ï¼Œæœ€å¤§å¹¶å‘æ•°è®¾ä¸º 4ï¼ˆå¯æ ¹æ®æ¼”ç¤ºéœ€è¦è°ƒæ•´ï¼‰
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {} # æ˜ å°„ï¼šFutureå¯¹è±¡ -> node_id

            # === äº‹ä»¶é©±åŠ¨å¾ªçŽ¯ ===
            while pending_ids or futures:
                # 1. æ‰«æå¯è¿è¡Œçš„èŠ‚ç‚¹
                # æ¡ä»¶ï¼šåœ¨ç­‰å¾…åˆ—è¡¨ + ä¾èµ–å…¨éƒ¨å®Œæˆ + æ²¡åœ¨è¿è¡Œ
                ready_nodes = []
                for nid in list(pending_ids): # ç”¨ list å¤åˆ¶ä¸€ä»½ä»¥é˜²éåŽ†æ—¶ä¿®æ”¹
                    if nid in running_ids:
                        continue
                        
                    node = all_nodes[nid]
                    deps = node.get("dependencies", [])
                    if all(d in completed_ids for d in deps):
                        ready_nodes.append(node)

                # 2. å‘å°„ä»»åŠ¡ (Launch)
                for node in ready_nodes:
                    nid = node['id']
                    # æäº¤ç»™çº¿ç¨‹æ± ï¼Œéžé˜»å¡ž
                    future = executor.submit(self.run_node, node)
                    futures[future] = nid
                    
                    # æ ‡è®°çŠ¶æ€
                    running_ids.add(nid)
                    # æ³¨æ„ï¼šæ­¤æ—¶ä¸èƒ½ä»Ž pending_ids åˆ é™¤ï¼Œè¦ç­‰çœŸæ­£å®Œæˆæ‰åˆ ï¼Œ
                    # æˆ–è€…çŽ°åœ¨åˆ ä¹Ÿè¡Œï¼Œä½†ä¸ºäº†é€»è¾‘æ¸…æ™°ï¼Œæˆ‘ä»¬åœ¨å®Œæˆæ—¶å¤„ç† pending

                if not futures and not ready_nodes:
                    print("[Scheduler] âŒ Deadlock or no nodes ready!")
                    break

                # 3. ç­‰å¾…ä»»æ„ä¸€ä¸ªä»»åŠ¡å®Œæˆ (Wait for Event)
                # return_when=FIRST_COMPLETED æ˜¯å®žçŽ°æµæ°´çº¿å¹¶è¡Œçš„å…³é”®
                if futures:
                    done, not_done = wait(futures.keys(), return_when=FIRST_COMPLETED)
                    
                    # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                    for f in done:
                        nid = futures.pop(f) # ä»Žç›‘æŽ§åˆ—è¡¨ä¸­ç§»é™¤
                        try:
                            success = f.result() # èŽ·å–è¿”å›žå€¼
                            if success:
                                completed_ids.add(nid)
                                pending_ids.remove(nid) # å½»åº•å®Œå·¥
                            else:
                                print(f"[Scheduler] âŒ Workflow aborted due to failure in {nid}")
                                return # ç®€å•èµ·è§ï¼Œæœ‰ä¸€ä¸ªå¤±è´¥å°±ç»ˆæ­¢
                        except Exception as e:
                            print(f"[Scheduler] ðŸ’¥ Exception in worker: {e}")
                            return
                        
                        running_ids.remove(nid)
            
        print(f"\n=== Workflow Completed Successfully! ===")
        print(f"Final Results:")
        for nid, res in self.results.items():
            # [ä¿®æ”¹] æ‰“å°å®Œæ•´å†…å®¹ï¼Œä¸å†æˆªæ–­
            print(f"\n>>>>> Node: [{nid}] <<<<<")
            print(res['content'])
            print("-" * 40)

if __name__ == "__main__":
    workflow_file = "example-apps/workflow_demo.json"
    try:
        scheduler = PieScheduler(workflow_file)
        scheduler.run()
    except FileNotFoundError as e:
        print(f"Error: {e}")
        sys.exit(1)